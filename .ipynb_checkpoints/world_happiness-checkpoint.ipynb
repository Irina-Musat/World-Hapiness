{"cells":[{"cell_type":"code","execution_count":2,"id":"25d3d5e9-7287-465e-a68b-bd30c6872f62","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\pylab.py:103\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;241m%\u001b[39m _list_matplotlib_backends_and_gui_loops()\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3665\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3662\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m\n\u001b[0;32m   3664\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[1;32m-> 3665\u001b[0m gui, backend \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3668\u001b[0m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[0;32m   3669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\pylabtools.py:338\u001b[0m, in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_gui_and_backend\u001b[39m(gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, gui_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a gui string return the gui and mpl backend.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m    'WXAgg','Qt4Agg','module://matplotlib_inline.backend_inline','agg').\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _matplotlib_manages_backends():\n\u001b[0;32m    341\u001b[0m         backend_registry \u001b[38;5;241m=\u001b[39m matplotlib\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mbackend_registry\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"]}],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"id":"e085786d-d473-421d-a3a9-cad8824742a1","metadata":{},"outputs":[],"source":["df = pd.read_csv('world-happiness-report.csv')"]},{"cell_type":"code","execution_count":null,"id":"2069c6ae-a3ef-402d-83aa-59fce312af14","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"id":"554f16a5-61f1-407c-93d3-ad5f95d862d4","metadata":{},"outputs":[],"source":["# Check for missing values in the dataset\n","missing_values = df.isnull().sum()\n","\n","# Print the missing values\n","print(missing_values)"]},{"cell_type":"code","execution_count":null,"id":"e7e5e77d-6ce9-44e9-92dc-59c141bc0890","metadata":{},"outputs":[],"source":["# Replace missing values with the mean of each column\n","df['Log GDP per capita'].fillna(df['Log GDP per capita'].mean(), inplace=True)\n","df['Social support'].fillna(df['Social support'].mean(), inplace=True)\n","df['Healthy life expectancy at birth'].fillna(df['Healthy life expectancy at birth'].mean(), inplace=True)\n","df['Freedom to make life choices'].fillna(df['Freedom to make life choices'].mean(), inplace=True)\n","df['Generosity'].fillna(df['Generosity'].mean(), inplace=True)\n","df['Perceptions of corruption'].fillna(df['Perceptions of corruption'].mean(), inplace=True)\n","df['Positive affect'].fillna(df['Positive affect'].mean(), inplace=True)\n","df['Negative affect'].fillna(df['Negative affect'].mean(), inplace=True)\n","\n","# Print the updated DataFrame\n","print(df)"]},{"cell_type":"code","execution_count":null,"id":"c21758d5-0543-4488-8e0d-a83a65b4192e","metadata":{},"outputs":[],"source":["df2 = pd.read_csv('world-happiness-report-2021.csv')"]},{"cell_type":"code","execution_count":null,"id":"4ee6c2c4-3d7e-4ce1-8277-456c5bf45b55","metadata":{},"outputs":[],"source":["df2.head()"]},{"cell_type":"code","execution_count":null,"id":"6bed08be-3f87-46c8-b3e0-9b60fd50040b","metadata":{},"outputs":[],"source":["# Check the data types of each column\n","print(df2.dtypes)"]},{"cell_type":"code","execution_count":null,"id":"6500110b-d8f5-4473-acdd-b7475da64557","metadata":{},"outputs":[],"source":["descriptions = {\n","    'Country name': 'Name of the country',\n","    'Regional indicator': 'Region of the country',\n","    'Ladder score': 'Happiness score based on survey responses',\n","    'Standard error of ladder score': 'Standard error of the ladder score',\n","    'upperwhisker': 'Upper whisker of the ladder score',\n","    'lowerwhisker': 'Lower whisker of the ladder score',\n","    'Logged GDP per capita': 'Natural logarithm of the GDP per capita',\n","    'Social support': 'Perceived social support',\n","    'Healthy life expectancy': 'Healthy life expectancy at birth',\n","    'Freedom to make life choices': 'Perceived freedom to make life choices',\n","    'Generosity': 'Generosity score based on survey responses',\n","    'Perceptions of corruption': 'Perceived corruption level',\n","    'Ladder score in Dystopia': 'Happiness score in a hypothetical country called Dystopia',\n","    'Explained by: Log GDP per capita': 'Extent to which the GDP per capita explains the happiness score',\n","    'Explained by: Social support': 'Extent to which social support explains the happiness score',\n","    'Explained by: Healthy life expectancy': 'Extent to which healthy life expectancy explains the happiness score',\n","    'Explained by: Freedom to make life choices': 'Extent to which freedom to make life choices explains the happiness score',\n","    'Explained by: Generosity': 'Extent to which generosity explains the happiness score',\n","    'Explained by: Perceptions of corruption': 'Extent to which perceptions of corruption explain the happiness score',\n","    'Dystopia + residual': 'Dystopia happiness score plus residual'\n","}"]},{"cell_type":"code","execution_count":null,"id":"4c24243a-f429-454a-b96d-32f1118a9bca","metadata":{},"outputs":[],"source":["# Check for missing values in the dataset\n","missing_values = df2.isnull().sum()\n","\n","# Print the missing values\n","print(missing_values)"]},{"cell_type":"code","execution_count":null,"id":"478b4deb-6d3c-4b1d-83c0-a97af7283ca9","metadata":{},"outputs":[],"source":["# Add descriptions for the variables\n","variable_descriptions = {\n","    'Country name': 'Name of the country',\n","    'year': 'Year of the observation',\n","    'Life Ladder': 'Measure of life satisfaction or happiness',\n","    'Log GDP per capita': 'Logarithm of GDP per capita, a measure of economic performance',\n","    'Social support': 'Perceived social support',\n","    'Healthy life expectancy at birth': 'Average number of years a newborn is expected to live in good health',\n","    'Freedom to make life choices': 'Perceived freedom to make life choices',\n","    'Generosity': 'Perceived generosity',\n","    'Perceptions of corruption': 'Perceived level of corruption in the country',\n","    'Positive affect': 'Measure of positive emotions or affect',\n","    'Negative affect': 'Measure of negative emotions or affect'\n","}"]},{"cell_type":"code","execution_count":null,"id":"29c9856f-56dc-4f15-99a0-1615bd697f35","metadata":{},"outputs":[],"source":["\n","# Print the variable descriptions\n","for variable, description in variable_descriptions.items():\n","    print(f\"{variable}: {description}\")\n"]},{"cell_type":"code","execution_count":null,"id":"2505c6f4-c3ab-44fc-8575-f785d0802bfd","metadata":{},"outputs":[],"source":["\n","# You can also provide the source of the dataset\n","source = \"The World Happiness Report 2021\"\n","print(f\"Source: {source}\")"]},{"cell_type":"markdown","id":"1b1f832e-a943-4a8b-9ca4-56a5ce571267","metadata":{},"source":["# User\n","The target variable that our analysis will focus on is the \"Ladder score\" or \"Ladder score in Dystopia\". These variables represent the measure of life satisfaction or happiness in the dataset. The \"Ladder score\" is the main variable of interest, while \"Ladder score in Dystopia\" provides a reference point for the lowest possible happiness score in the dataset.\n","\n","Therefore, our analysis will primarily focus on understanding and exploring the factors that influence the \"Ladder score\" or \"Ladder score in Dystopia\" and how other variables in the dataset contribute to or explain variations in the happiness scores across different regions or countries.bles"]},{"cell_type":"code","execution_count":null,"id":"605dc44a-ff22-457c-be64-1459bba98699","metadata":{},"outputs":[],"source":["# Line plot for Ladder score across Regional indicators\n","plt.figure(figsize=(12, 8))\n","lineplot = sns.lineplot(x='Regional indicator', y='Ladder score', data=df2, ci=None)\n","lineplot.set_title('Ladder Score Across Regional Indicators')\n","lineplot.set_xlabel('Regional Indicator')\n","lineplot.set_ylabel('Ladder Score')\n","lineplot.set_xticklabels(lineplot.get_xticklabels(), rotation=45, horizontalalignment='right')  # Rotate x-axis labels for better visibility\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"9912c41b-1895-4d9f-ae5c-77a18d700312","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n","boxplot = sns.boxplot(y='Ladder score', data=df2)\n","boxplot.set_title('Distribution of Ladder Score')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"3ed5bd56-5cae-4f71-a6f9-a336a5a95514","metadata":{},"outputs":[],"source":["# Select numeric columns for correlation calculation\n","numeric_columns = df2.select_dtypes(include=['float64', 'int64'])\n","\n","# Calculate the correlation matrix\n","correlation_matrix = numeric_columns.corr()\n","\n","# Create a heatmap of correlations\n","plt.figure(figsize=(12, 10))\n","heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n","heatmap.set_title('Correlation Heatmap')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"291257dd-b6e3-48ff-ad36-9b5c5b70e8a0","metadata":{},"outputs":[],"source":["from scipy import stats\n","\n","# Perform Pearson correlation test\n","pearson_corr, pearson_p_value = stats.pearsonr(df2['Ladder score'], df2['Logged GDP per capita'])\n","\n","# Print the correlation coefficient and p-value\n","print(\"Pearson correlation coefficient:\", pearson_corr)\n","print(\"P-value:\", pearson_p_value)"]},{"cell_type":"code","execution_count":null,"id":"f989b119-6e13-4b04-afd7-be56805273ff","metadata":{},"outputs":[],"source":["# Scatter plot for Ladder score vs. Logged GDP per capita\n","plt.figure(figsize=(8, 6))\n","scatterplot = sns.scatterplot(x='Logged GDP per capita', y='Ladder score', data=df2)\n","scatterplot.set_title('Ladder Score vs. Logged GDP per Capita')\n","scatterplot.set_xlabel('Logged GDP per Capita')\n","scatterplot.set_ylabel('Ladder Score')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"fc3cb8ab-cfee-45db-b32d-68b115bd4d40","metadata":{},"outputs":[],"source":["# Histogram of Ladder score\n","plt.figure(figsize=(8, 6))\n","histogram = sns.histplot(df2['Ladder score'], kde=True)\n","histogram.set_title('Distribution of Ladder Score')\n","histogram.set_xlabel('Ladder Score')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"3bbd111d-ce35-477b-a832-56b4103f6365","metadata":{},"outputs":[],"source":["# Bar chart for average Ladder score by Regional indicator\n","average_ladder_by_region = df2.groupby('Regional indicator')['Ladder score'].mean().sort_values(ascending=False)\n","plt.figure(figsize=(12, 8))\n","bar_chart = average_ladder_by_region.plot(kind='bar', color='skyblue')\n","bar_chart.set_title('Average Ladder Score by Regional Indicator')\n","bar_chart.set_xlabel('Regional Indicator')\n","bar_chart.set_ylabel('Average Ladder Score')\n","plt.xticks(rotation=45, ha='right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"282252cf-9a15-41b6-b016-ec690a15c010","metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, ElasticNet\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","# Example data (replace with your actual data)\n","# Assume we have a DataFrame 'df' with columns: 'year', 'GDP', 'Population', etc.\n","# You'll need to load your own data here.\n","\n","# Prepare data\n","X = df[['year']]  # Features (e.g., year)\n","y = df[['Log GDP per capita']]\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize models\n","linear_reg = LinearRegression()\n","ridge_model = Ridge()\n","lasso_model = Lasso()\n","lasso_cv_model = LassoCV()\n","elastic_net_model = ElasticNet()\n","decision_tree = DecisionTreeRegressor()\n","random_forest = RandomForestRegressor()\n","gb_model = GradientBoostingRegressor()\n","\n","# Train models\n","linear_reg.fit(X_train, y_train)\n","ridge_model.fit(X_train, y_train)\n","lasso_model.fit(X_train, y_train)\n","lasso_cv_model.fit(X_train, y_train.values.ravel())\n","elastic_net_model.fit(X_train, y_train)\n","decision_tree.fit(X_train, y_train)\n","random_forest.fit(X_train, y_train)\n","gb_model.fit(X_train, y_train.values.ravel())\n","\n","# Make predictions\n","y_pred_linear = linear_reg.predict(X_test)\n","y_pred_ridge = ridge_model.predict(X_test)\n","y_pred_lasso = lasso_model.predict(X_test)\n","y_pred_lasso_cv = lasso_cv_model.predict(X_test)\n","y_pred_elastic_net = elastic_net_model.predict(X_test)\n","y_pred_tree = decision_tree.predict(X_test)\n","y_pred_rf = random_forest.predict(X_test)\n","y_pred_gb = gb_model.predict(X_test)\n","\n","# Evaluate models (using Mean Squared Error)\n","mse_linear = mean_squared_error(y_test, y_pred_linear)\n","mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n","mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n","mse_lasso_cv = mean_squared_error(y_test, y_pred_lasso_cv)\n","mse_elastic_net = mean_squared_error(y_test, y_pred_elastic_net)\n","mse_tree = mean_squared_error(y_test, y_pred_tree)\n","mse_rf = mean_squared_error(y_test, y_pred_rf)\n","mse_gb = mean_squared_error(y_test, y_pred_gb)\n","\n","print(f\"Linear Regression MSE: {mse_linear:.2f}\")\n","print(f\"Ridge Regression MSE: {mse_ridge:.2f}\")\n","print(f\"Lasso Regression MSE: {mse_lasso:.2f}\")\n","print(f\"LassoCV Regression MSE: {mse_lasso_cv:.2f}\")\n","print(f\"ElasticNet Regression MSE: {mse_elastic_net:.2f}\")\n","print(f\"Decision Tree MSE: {mse_tree:.2f}\")\n","print(f\"Random Forest MSE: {mse_rf:.2f}\")\n","print(f\"Gradient Boosting MSE: {mse_gb:.2f}\")"]},{"cell_type":"code","execution_count":null,"id":"1c96b133-210f-492a-97f7-da91dbd581d5","metadata":{},"outputs":[],"source":["#By running the provided code, you will be able to compare the performance of various regression models in predicting the 'Log GDP per capita' based on the 'year' feature. Here's what you can find out from the code:\n","\n","1. **Model Performance**: You will obtain the Mean Squared Error (MSE) for each model, which measures the average squared difference between the actual and predicted values. Lower MSE indicates better model performance.\n","\n","2. **Comparison of Models**: You can compare the MSE of different regression models (Linear Regression, Ridge Regression, Lasso Regression, LassoCV, ElasticNet, Decision Tree, Random Forest, and Gradient Boosting) to determine which model provides the most accurate predictions for the given dataset.\n","\n","3. **Model Selection**: Based on the MSE values, you can select the model that performs best for predicting 'Log GDP per capita' using the 'year' feature. The model with the lowest MSE may be considered the most suitable for this specific prediction task.\n","\n","4. **Insights into Feature Importance**: For tree-based models (Decision Tree, Random Forest, Gradient Boosting), you can also gain insights into the importance of the 'year' feature in predicting 'Log GDP per capita'.\n","\n","Overall, running this code will provide valuable insights into the predictive performance of different regression models and help in selecting the most appropriate model for predicting 'Log GDP per capita' based on the 'year' feature."]},{"cell_type":"code","execution_count":null,"id":"acbba018-0e01-4ff1-8517-6cea72e88dd7","metadata":{},"outputs":[],"source":["from sklearn.metrics import r2_score, mean_absolute_error\n","from math import sqrt\n","\n","# Example for Linear Regression model\n","# Evaluate R² of train and test\n","r2_train = linear_reg.score(X_train, y_train)\n","r2_test = linear_reg.score(X_test, y_test)\n","\n","# Evaluate MAE\n","mae = mean_absolute_error(y_test, y_pred_linear)\n","\n","# Evaluate MSE\n","mse = mean_squared_error(y_test, y_pred_linear)\n","\n","# Evaluate RMSE\n","rmse = sqrt(mse)\n","\n","print(\"Linear Regression Model Evaluation:\")\n","print(f\"R² (Train): {r2_train:.2f}\")\n","print(f\"R² (Test): {r2_test:.2f}\")\n","print(f\"MAE: {mae:.2f}\")\n","print(f\"MSE: {mse:.2f}\")\n","print(f\"RMSE: {rmse:.2f}\")"]},{"cell_type":"code","execution_count":null,"id":"3b46f6d1-e9ca-4a66-bdbd-ed2ad655629c","metadata":{},"outputs":[],"source":["# Example for Random Forest model\n","# Get feature importances\n","feature_importances = random_forest.feature_importances_\n","\n","# Create a bar plot of feature importances\n","plt.figure(figsize=(10, 6))\n","plt.bar(X.columns, feature_importances)\n","plt.xlabel('Feature')\n","plt.ylabel('Importance')\n","plt.title('Feature Importances - Random Forest Model')\n","plt.xticks(rotation=45)\n","plt.show()\n","#To evaluate the models with a bar plot of feature importances and a \n","#scatter plot of target versus prediction, you can use the following code. \n","#I will provide an example for the Random Forest model, and you can extend it \n","#to the other models accordingly.\n","\n","#First, let's start with the bar plot of feature importances for the Random Forest \n","#model:"]},{"cell_type":"code","execution_count":null,"id":"f4c8261d-b894-44bc-8c4d-acdb4de484c5","metadata":{},"outputs":[],"source":["# Create a scatter plot of target versus prediction\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, y_pred_rf)\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n","plt.xlabel('True Values')\n","plt.ylabel('Predictions')\n","plt.title('Random Forest Model: True Values vs. Predictions')\n","plt.show()\n","#You can extend this evaluation to the other models (Linear Regression, \n","#Ridge Regression, Lasso Regression, LassoCV, ElasticNet, Decision Tree, and \n","#Gradient Boosting) by replacing the model names and predictions accordingly.\n","\n","#By running this code for each model, you will be able to visualize the feature\n","#importances and the relationship between the true target values and the model \n","#predictions, providing insights into the model's performance and the importance \n","#of features in making predictions."]},{"cell_type":"code","execution_count":null,"id":"c8679f92-dcec-49dd-b98b-b4f45bde9ad7","metadata":{},"outputs":[],"source":["countries = ['Germany', 'France', 'Romania', 'Armenia', 'United States', 'Bangladesh']\n","gdp_2040 = [5.2, 4.8, 0.9, 0.2, 25.0, 1.5]  # Hypothetical GDP values (scaled for illustration)\n","\n","plt.figure(figsize=(10, 6))\n","plt.bar(countries, gdp_2040, color='skyblue')\n","plt.xlabel('Countries')\n","plt.ylabel('GDP (trillion USD)')\n","plt.title('Projected GDP in 2040')\n","plt.grid(axis='y')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"05c04333-dca3-4ee0-9a2c-65239ecff24c","metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Load the dataframes from the uploaded files\n","df1 = pd.read_csv('world-happiness-report.csv')\n","df2 = pd.read_csv('world-happiness-report-2021.csv')\n","\n","# Strip any leading or trailing spaces from the column names\n","df1.columns = df1.columns.str.strip()\n","df2.columns = df2.columns.str.strip()\n","\n","# Strip any leading or trailing spaces from the 'Country name' values\n","df1['Country name'] = df1['Country name'].str.strip()\n","df2['Country name'] = df2['Country name'].str.strip()\n","\n","# Merging the dataframes on the 'Country name' column\n","merged_df = pd.merge(df1, df2, on='Country name')\n","\n","# Show the first few rows of the merged dataframe\n","merged_df.head()"]},{"cell_type":"code","execution_count":null,"id":"2a52e83e-1a9d-45e7-9d29-23b48add1253","metadata":{},"outputs":[],"source":["merged_df.info()"]},{"cell_type":"code","execution_count":null,"id":"b72fd992-6655-4854-baca-098ef278e1cd","metadata":{},"outputs":[],"source":["# Select the relevant columns for the plot\n","plot_df = merged_df[['Country name', 'year', 'Life Ladder', 'Perceptions of corruption_x', 'Regional indicator']]\n","\n","# Rename columns for consistency\n","plot_df.columns = ['Country name', 'Year', 'Life Ladder', 'Perceptions of corruption', 'Region']\n","\n","# Create the plot\n","fig = px.scatter(plot_df,\n","                 x=\"Perceptions of corruption\",\n","                 y=\"Life Ladder\",\n","                 animation_frame=\"Year\",\n","                 animation_group=\"Country name\",\n","                 template=\"plotly_dark\",\n","                 color=\"Region\",\n","                 hover_name=\"Country name\",\n","                 size_max=60)\n","fig.update_layout(title=\"Life Ladder and Corruption Comparison by Countries via Regions for each Year\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"834f605a-d3e4-4c73-b775-a76c4093dfde","metadata":{},"outputs":[],"source":["The generated plot is a dynamic scatter plot created using Plotly Express, which \n","visualizes the relationship between \"Life Ladder\" (a measure of life satisfaction \n","or happiness) and \"Perceptions of corruption\" for various countries over different \n","years. Here's a breakdown of its components and functionality:\n","\n","Axes:\n","\n","X-axis: Represents the \"Perceptions of corruption\". Lower values on this axis \n","indicate lower levels of perceived corruption, while higher values indicate higher \n","levels of perceived corruption.\n","Y-axis: Represents the \"Life Ladder\" score, which measures the happiness or life \n","satisfaction of people in each country. Higher values on this axis indicate higher \n","life satisfaction.\n","\n","Data Points:\n","\n","Each dot in the plot represents a country for a specific year.\n","The color of each dot corresponds to the region of the world the country belongs to,\n","as indicated by the legend on the right.\n","The size of the dots can be adjusted, although in this case, it seems that the size\n","is not set to represent any variable such as population.\n","\n","Animation:\n","\n","The plot includes a slider and play button at the bottom, allowing you to animate \n","the data over time.\n","As the slider moves from one year to the next, the position of the dots changes to \n","reflect the data for that specific year.\n","This dynamic feature helps in visualizing how the relationship between happiness \n","and perceptions of corruption changes over time for different countries and regions.\n","\n","Interactivity:\n","\n","You can hover over each dot to see detailed information about the country it \n","represents, including the country name, the region, and the exact values for \n","\"Life Ladder\" and \"Perceptions of corruption\".\n","The legend on the right allows you to identify which color corresponds to which \n","region.\n","                                                                        \n","Title and Layout:\n","\n","The title of the plot is \"Life Ladder and Corruption Comparison by Countries via Regions for each Year\",\n","which explains the purpose of the visualization.\n","The plot uses a dark template (plotly_dark), which gives it a specific aesthetic.\n","In summary, this plot provides an interactive and animated visualization to compare\n","and understand the relationship between happiness and perceptions of corruption \n","across different countries and regions over time. It allows users to see trends \n","and changes in these metrics from year to year."]},{"cell_type":"code","execution_count":null,"id":"4d58ee97-5558-4623-aad9-98f93e705dde","metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# Filter the relevant columns\n","df = merged_df[['Country name', 'year', 'Life Ladder']]\n","\n","# List of countries to predict for\n","countries_to_predict = df['Country name'].unique()\n","\n","# Dictionary to store the predictions\n","predictions_2040 = {}\n","\n","# Loop through each country and train a model to predict the 2040 happiness score\n","for country in countries_to_predict:\n","    df_country = df[df['Country name'] == country]\n","    X = df_country['year'].values.reshape(-1, 1)\n","    y = df_country['Life Ladder'].values\n","    \n","    model = LinearRegression()\n","    model.fit(X, y)\n","    \n","    # Predict the happiness score for the year 2040\n","    prediction_2040 = model.predict(np.array([[2040]]))\n","    predictions_2040[country] = prediction_2040[0]\n","\n","# Convert the predictions to a DataFrame for better visualization\n","df_predictions_2040 = pd.DataFrame(predictions_2040.items(), columns=['Country', 'Predicted Happiness Score 2040'])\n","\n","# Display the predictions\n","print(df_predictions_2040)\n","\n","df_predictions_2040\n","\n"]},{"cell_type":"code","execution_count":null,"id":"00db3507-d03e-4fe4-bf9e-88dc775d9700","metadata":{},"outputs":[],"source":["from scipy import stats\n","# Generate descriptive statistics for the merged dataframe\n","descriptive_stats = merged_df.describe()\n","print(descriptive_stats)\n","\n","# Create visualizations\n","# Example: Histogram of Life Ladder\n","plt.figure(figsize=(8, 6))\n","sns.histplot(merged_df['Life Ladder'], kde=True)\n","plt.title('Distribution of Life Ladder')\n","plt.xlabel('Life Ladder')\n","plt.ylabel('Frequency')\n","plt.show()\n","\n","# Example: Box plot of Life Ladder by Regional indicator\n","plt.figure(figsize=(10, 8))\n","sns.boxplot(x='Regional indicator', y='Life Ladder', data=merged_df)\n","plt.title('Life Ladder by Regional indicator')\n","plt.xlabel('Regional indicator')\n","plt.ylabel('Life Ladder')\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","# Example: Scatter plot of Life Ladder vs. Logged GDP per capita\n","plt.figure(figsize=(8, 6))\n","sns.scatterplot(x='Logged GDP per capita', y='Life Ladder', data=merged_df)\n","plt.title('Life Ladder vs. Logged GDP per capita')\n","plt.xlabel('Logged GDP per capita')\n","plt.ylabel('Life Ladder')\n","plt.show()\n","\n","# Perform statistical tests if necessary\n","# Example: t-test to compare Life Ladder between two groups\n","group1 = merged_df[merged_df['Regional indicator'] == 'Group1']['Life Ladder']\n","group2 = merged_df[merged_df['Regional indicator'] == 'Group2']['Life Ladder']\n","t_stat, p_value = stats.ttest_ind(group1, group2)\n","print('t-statistic:', t_stat)\n","print('p-value:', p_value)"]},{"cell_type":"code","execution_count":null,"id":"7004b0bb-a8e9-4f18-aff0-3c3ca74062e4","metadata":{},"outputs":[],"source":["# Example: Create a new feature 'GDP per capita squared'\n","merged_df['GDP per capita squared'] = merged_df['Logged GDP per capita'] ** 2\n","\n","# Example: Create a new feature 'Social support * Healthy life expectancy'\n","# Assuming 'Social support_x' and 'Healthy life expectancy' are the correct columns\n","merged_df['Support * Life Expectancy'] = merged_df['Social support_x'] * merged_df['Healthy life expectancy']\n","\n","# Example: Create a new feature 'Perceived Happiness' based on Positive and Negative affect\n","# Assuming 'Positive affect' and 'Negative affect' are the correct columns for Perceived Happiness\n","merged_df['Perceived Happiness'] = merged_df['Positive affect'] - merged_df['Negative affect']\n","\n","# Display the first few rows of the dataframe with the new features\n","print(merged_df.head())"]},{"cell_type":"code","execution_count":null,"id":"412f3b9e-7bf0-48e6-a4b7-b0ed5dcfb96f","metadata":{},"outputs":[],"source":["# Checking the column names in the merged dataframe\n","print(merged_df.columns)\n","\n","# Example: Create a new feature 'Logged GDP per capita squared'\n","merged_df['Logged GDP per capita squared'] = merged_df['Logged GDP per capita'] ** 2\n","\n","# Example: Create a new feature 'Social support * Healthy life expectancy'\n","merged_df['Support * Life Expectancy'] = merged_df['Social support_x'] * merged_df['Healthy life expectancy']\n","\n","# Example: Create a new feature 'Perceived Happiness' based on Positive and Negative affect\n","merged_df['Perceived Happiness'] = merged_df['Positive affect'] - merged_df['Negative affect']\n","\n","# Display the first few rows of the dataframe with the new features\n","merged_df.head()"]},{"cell_type":"code","execution_count":null,"id":"5efd3fef-5f79-45c2-ab06-981317366350","metadata":{},"outputs":[],"source":["import plotly.express as px\n","\n","fig = px.choropleth(df1, locations=\"Country name\", locationmode=\"country names\", color=\"Life Ladder\",\n","                    color_continuous_scale=px.colors.sequential.Plasma,\n","                    title=\"World Heatmap\")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"057b6942-d336-4d47-ab78-650c750304ab","metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, ElasticNet\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","\n","# Linear Regression\n","model1 = LinearRegression()\n","model1.fit(X, y)\n","\n","# Decision Tree Regressor\n","model2 = DecisionTreeRegressor()\n","model2.fit(X, y)\n","\n","# Lasso\n","model3 = Lasso()\n","model3.fit(X, y)\n","\n","# Gradient Boosting Regressor\n","model4 = GradientBoostingRegressor()\n","model4.fit(X, y)\n","\n","# Ridge\n","model5 = Ridge()\n","model5.fit(X, y)\n","\n","# Random Forest Regressor\n","model6 = RandomForestRegressor()\n","model6.fit(X, y)\n","\n","# LassoCV\n","model7 = LassoCV()\n","model7.fit(X, y)\n","\n","# ElasticNet\n","model8 = ElasticNet()\n","model8.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"9374954c-c0e5-41fd-b6f0-57198992798b","metadata":{},"outputs":[],"source":["# Plotting the Linear Regression results\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x=X.flatten(), y=y, color='blue', label='Actual')\n","sns.lineplot(x=X.flatten(), y=model1.predict(X), color='red', label='Linear Regression')\n","plt.title('Linear Regression Model')\n","plt.xlabel('Logged GDP per capita')\n","plt.ylabel('Life Ladder')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e040418e-4e36-4f4d-b47d-c5b3ba8d2f36","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"id":"69d8720e-be6a-4e40-ae85-a28f1963d072","metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, ElasticNet\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","from sklearn.model_selection import GridSearchCV\n","\n","# Initialize models with max_depth parameter\n","lr = LinearRegression()\n","dt = DecisionTreeRegressor()\n","rf = RandomForestRegressor()\n","rm = Ridge()\n","gb = GradientBoostingRegressor()\n","lasso = Lasso()\n","lasso_cv = LassoCV()\n","elastic_net = ElasticNet()\n","\n","#ATTEMPTS TO AVOID OVERFITTING  - Decision Tree\tTrain Set\n","\n","\n","# Use Cross-Validation for Hyperparameter Tuning\n","dt_parameters = {\n","    'max_depth': [3, 5, 7, 10],\n","    'min_samples_split': [2, 5, 10, 20],\n","    'min_samples_leaf': [1, 2, 5, 10, 50]}\n","# Perform Grid Search Cross-Validation\n","clf = GridSearchCV(dt, dt_parameters, cv=5, scoring='neg_mean_squared_error')\n","clf.fit(X_train_scaled, y_train)\n","\n","# Get the best hyperparameters\n","best_params = clf.best_params_\n","print(\"Best Hyperparameters for Decision Tree:\", best_params)\n","# Initialize Decision Tree model with best hyperparameters\n","best_dt = DecisionTreeRegressor(max_depth=best_params['max_depth'],\n","                                min_samples_split=best_params['min_samples_split'],\n","                                min_samples_leaf=best_params['min_samples_leaf'])\n","\n","# Train the final model with the best parameters\n","best_dt.fit(X_train_scaled, y_train)\n","\n","# Calculate the effective alphas for pruning\n","path = dt.cost_complexity_pruning_path(X_train_scaled, y_train)\n","ccp_alphas, impurities = path.ccp_alphas, path.impurities\n","\n","# Train a series of models with different alphas\n","models = []\n","for ccp_alpha in ccp_alphas:\n","    model = DecisionTreeRegressor(ccp_alpha=ccp_alpha)\n","    model.fit(X_train_scaled, y_train)\n","    models.append(model)\n","\n","# Evaluate the models on the testing data\n","train_scores = [model.score(X_train_scaled, y_train) for model in models]\n","test_scores = [model.score(X_test_scaled, y_test) for model in models]\n","\n","# Plot the alpha vs. R-squared for training and testing sets\n","plt.figure(figsize=(10, 6))\n","plt.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle=\"steps-post\")\n","plt.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle=\"steps-post\")\n","plt.xlabel(\"alpha\")\n","plt.ylabel(\"R-squared\")\n","plt.title(\"Alpha vs. R-squared for Training and Testing Sets\")\n","plt.legend()\n","plt.show()\n","\n","# Train final model with the best ccp_alpha\n","# Identify the best ccp_alpha\n","best_ccp_alpha = 0.005  # Replace with the best ccp_alpha identified from Cost Complexity Pruning\n","\n","# Initialize Decision Tree model with the best ccp_alpha\n","final_dt = DecisionTreeRegressor(ccp_alpha=best_ccp_alpha)\n","\n","# Train the final model with the best ccp_alpha\n","final_dt.fit(X_train_scaled, y_train)\n","\n","\n","\n","\n","# Fit models\n","lr.fit(X_train_scaled, y_train)\n","dt.fit(X_train_scaled, y_train)\n","rf.fit(X_train_scaled, y_train)\n","rm.fit(X_train_scaled, y_train)\n","gb.fit(X_train_scaled, y_train)\n","lasso.fit(X_train_scaled, y_train)\n","lasso_cv.fit(X_train_scaled, y_train)\n","elastic_net.fit(X_train_scaled, y_train)\n","\n","# Predict\n","\n","lr_pred_train = lr.predict(X_train_scaled)\n","dt_pred_train = dt.predict(X_train_scaled)\n","rf_pred_train = rf.predict(X_train_scaled)\n","rm_pred_train = rm.predict(X_train_scaled)\n","gb_pred_train = gb.predict(X_train_scaled)\n","lasso_pred_train = lasso.predict(X_train_scaled)\n","lasso_cv_pred_train = lasso_cv.predict(X_train_scaled)\n","elastic_net_pred_train = elastic_net.predict(X_train_scaled)\n","\n","lr_pred_test = lr.predict(X_test_scaled)\n","dt_pred_test = dt.predict(X_test_scaled)\n","rf_pred_test = rf.predict(X_test_scaled)\n","rm_pred_test = rm.predict(X_test_scaled)\n","gb_pred_test = gb.predict(X_test_scaled)\n","lasso_pred_test = lasso.predict(X_test_scaled)\n","lasso_cv_pred_test = lasso_cv.predict(X_test_scaled)\n","elastic_net_pred_test = elastic_net.predict(X_test_scaled)"]},{"cell_type":"code","execution_count":null,"id":"a917cbe8-7488-4df3-a183-af29351c498c","metadata":{},"outputs":[],"source":["models = ['Linear Regression', 'Decision Tree', 'Random Forest', 'Ridge', 'Gradient Boosting', 'Lasso', 'LassoCV', 'ElasticNet']\n","train_r2 = [0.753, 1.0, 0.979, 0.753, 0.878, 0.0, 0.753, 0.396]\n","test_r2 = [0.75, 0.732, 0.862, 0.75, 0.813, 0.0, 0.75, 0.391]\n","train_mse = [0.321, 0.0, 0.027, 0.321, 0.159, 1.298, 0.321, 0.784]\n","test_mse = [0.316, 0.338, 0.174, 0.316, 0.236, 1.263, 0.316, 0.769]\n","\n","# Set up the figure and axes\n","fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n","\n","# Plot R² scores\n","axs[0].bar(np.arange(len(models)), train_r2, width=0.4, label='Train R²', align='center')\n","axs[0].bar(np.arange(len(models)) + 0.4, test_r2, width=0.4, label='Test R²', align='center')\n","axs[0].set_xticks(np.arange(len(models)) + 0.2)\n","axs[0].set_xticklabels(models, rotation=45, ha='right')\n","axs[0].set_title('R² Scores')\n","axs[0].set_ylabel('R²')\n","axs[0].legend()\n","\n","# Plot MSE\n","axs[1].bar(np.arange(len(models)), train_mse, width=0.4, label='Train MSE', align='center')\n","axs[1].bar(np.arange(len(models)) + 0.4, test_mse, width=0.4, label='Test MSE', align='center')\n","axs[1].set_xticks(np.arange(len(models)) + 0.2)\n","axs[1].set_xticklabels(models, rotation=45, ha='right')\n","axs[1].set_title('Mean Squared Error (MSE)')\n","axs[1].set_ylabel('MSE')\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"34f6edbc-0ab4-4b16-affb-59eaaf389696","metadata":{},"outputs":[],"source":["# Lists to store scores\n","train_scores = []\n","test_scores = []\n","max_depths = range(1, 21)\n","\n","# Iterate over values of max_depth\n","for max_depth in max_depths:\n","    model = RandomForestRegressor(max_depth=max_depth, random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    # Predictions\n","    y_train_pred = model.predict(X_train)\n","    y_test_pred = model.predict(X_test)\n","\n","    # Calculate R² scores\n","    train_r2 = r2_score(y_train, y_train_pred)\n","    test_r2 = r2_score(y_test, y_test_pred)\n","\n","    # Add scores to the lists\n","    train_scores.append(train_r2)\n","    test_scores.append(test_r2)\n","\n","# Plot the scores\n","plt.figure(figsize=(10, 6))\n","plt.plot(max_depths, train_scores, label='Train R²')\n","plt.plot(max_depths, test_scores, label='Test R²')\n","plt.xlabel('max_depth')\n","plt.ylabel('R² Score')\n","plt.title('Random Forest: max_depth vs R² Score')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"a4591b03-5913-4c52-9211-8b76e24199d2","metadata":{},"outputs":[],"source":["# Set up the figure and axes\n","fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n","\n","# Plot R² scores\n","axs[0].bar(np.arange(len(models)), train_r2, width=0.4, label='Train R²', align='center')\n","axs[0].bar(np.arange(len(models)) + 0.4, test_r2, width=0.4, label='Test R²', align='center')\n","axs[0].set_xticks(np.arange(len(models)) + 0.2)\n","axs[0].set_xticklabels(models, rotation=45, ha='right')\n","axs[0].set_title('R² Scores')\n","axs[0].set_ylabel('R²')\n","axs[0].legend()\n","\n","# Plot MSE\n","axs[1].bar(np.arange(len(models)), train_mse, width=0.4, label='Train MSE', align='center')\n","axs[1].bar(np.arange(len(models)) + 0.4, test_mse, width=0.4, label='Test MSE', align='center')\n","axs[1].set_xticks(np.arange(len(models)) + 0.2)\n","axs[1].set_xticklabels(models, rotation=45, ha='right')\n","axs[1].set_title('Mean Squared Error (MSE)')\n","axs[1].set_ylabel('MSE')\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0dfc6975-d368-41e9-93e2-b13799e37268","metadata":{},"outputs":[],"source":["# Import necessary libraries\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, ElasticNet\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","import numpy as np\n","\n","# Initialize models\n","lr = LinearRegression()\n","dt = DecisionTreeRegressor()\n","rf = RandomForestRegressor()\n","rm = Ridge()\n","gb = GradientBoostingRegressor()\n","lasso = Lasso()\n","lasso_cv = LassoCV()\n","elastic_net = ElasticNet()\n","\n","# List of models to evaluate\n","models = {\n","    \"Linear Regression\": lr,\n","    \"Decision Tree\": dt,\n","    \"Random Forest\": rf,\n","    \"Ridge\": rm,\n","    \"Gradient Boosting\": gb,\n","    \"Lasso\": lasso,\n","    \"LassoCV\": lasso_cv,\n","    \"ElasticNet\": elastic_net\n","}\n","\n","# Function to evaluate a model\n","def evaluate_model(model, X_train, y_train, X_test, y_test):\n","    model.fit(X_train, y_train.values.ravel())\n","    y_pred_train = model.predict(X_train)\n","    y_pred_test = model.predict(X_test)\n","\n","    mse_train = mean_squared_error(y_train, y_pred_train)\n","    mse_test = mean_squared_error(y_test, y_pred_test)\n","    r2_train = r2_score(y_train, y_pred_train)\n","    r2_test = r2_score(y_test, y_pred_test)\n","    mae_test = mean_absolute_error(y_test, y_pred_test)\n","    rmse_test = np.sqrt(mse_test)\n","\n","    print(f'{model.__class__.__name__} Evaluation:')\n","    print(f'R² Score (Train): {r2_train:.2f}')\n","    print(f'R² Score (Test): {r2_test:.2f}')\n","    print(f'Mean Absolute Error (Test): {mae_test:.2f}')\n","    print(f'Mean Squared Error (Train): {mse_train:.2f}')\n","    print(f'Mean Squared Error (Test): {mse_test:.2f}')\n","    print(f'Root Mean Squared Error (Test): {rmse_test:.2f}')\n","    if isinstance(model, (ElasticNet, LassoCV)):\n","        print(f'Optimal alpha: {model.alpha_:.4f}')\n","        if isinstance(model, ElasticNet):\n","            print(f'Optimal l1_ratio: {model.l1_ratio_:.2f}')\n","    print('')\n","\n","# Evaluate each model\n","for name, model in models.items():\n","    evaluate_model(model, X_train, y_train, X_test, y_test)\n"]},{"cell_type":"code","execution_count":null,"id":"fc88d8e4-9616-4205-86db-55bffb66083f","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}
